<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>GraphRAG services on ArangoDB Documentation</title><link>http://localhost/3.12/data-science/graphrag/services/</link><description>Recent content in GraphRAG services on ArangoDB Documentation</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><atom:link href="http://localhost/3.12/data-science/graphrag/services/index.xml" rel="self" type="application/rss+xml"/><item><title>GenAI Orchestration Service</title><link>http://localhost/3.12/data-science/graphrag/services/gen-ai/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://localhost/3.12/data-science/graphrag/services/gen-ai/</guid><description>ArangoDB Platform The ArangoDB Platform &amp;amp; GenAI Suite is available as a pre-release. To get exclusive early access, get in touch&amp;nbsp; with the ArangoDB team. Overview The basic operations that the GenAI orchestration service carries out are the following:
Install a service Uninstall a service Get the status of a service List all installed and deployed services Each unique service has its own API endpoint for the deployment.
Endpoint LLM Host: https://&amp;lt;ExternalEndpoint&amp;gt;:8529/gen-ai/v1/llmhost</description></item><item><title>Importer Service</title><link>http://localhost/3.12/data-science/graphrag/services/importer/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://localhost/3.12/data-science/graphrag/services/importer/</guid><description>ArangoDB Platform The ArangoDB Platform &amp;amp; GenAI Suite is available as a pre-release. To get exclusive early access, get in touch&amp;nbsp; with the ArangoDB team. Overview The Importer service lets you turn text files into a knowledge graph. It supports the following text formats with UTF-8 encoding:
.txt (Plain text) .md (Markdown) The Importer takes your text, analyzes it using the configured language model, and creates a structured knowledge graph.</description></item><item><title>Retriever Service</title><link>http://localhost/3.12/data-science/graphrag/services/retriever/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://localhost/3.12/data-science/graphrag/services/retriever/</guid><description>ArangoDB Platform The ArangoDB Platform &amp;amp; GenAI Suite is available as a pre-release. To get exclusive early access, get in touch&amp;nbsp; with the ArangoDB team. Overview The Retriever service offers two distinct search methods:
Global search: Analyzes entire document to identify themes and patterns, perfect for high-level insights and comprehensive summaries. Local search: Focuses on specific entities and their relationships, ideal for detailed queries about particular concepts. The service supports both private (Triton Inference Server) and public (OpenAI) LLM deployments, making it flexible for various security and infrastructure requirements.</description></item><item><title>ArangoDB MLflow Service</title><link>http://localhost/3.12/data-science/graphrag/services/mlflow/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://localhost/3.12/data-science/graphrag/services/mlflow/</guid><description>ArangoDB Platform The ArangoDB Platform &amp;amp; GenAI Suite is available as a pre-release. To get exclusive early access, get in touch&amp;nbsp; with the ArangoDB team. Overview The ArangoDB MLflow service is a service that hosts the official MLflow application in your Kubernetes cluster and connects automatically to the ArangoDB environment, e.g. for registering the LLM to be self-hosted and used by services requiring LLMs (such as the Importer and Retriever services).</description></item><item><title>Triton LLM Host</title><link>http://localhost/3.12/data-science/graphrag/services/triton-inference-server/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>http://localhost/3.12/data-science/graphrag/services/triton-inference-server/</guid><description>ArangoDB Platform The ArangoDB Platform &amp;amp; GenAI Suite is available as a pre-release. To get exclusive early access, get in touch&amp;nbsp; with the ArangoDB team. Overview The Triton LLM Host service provides scalable deployment of Large Language Models (LLMs) using the NVIDIA Triton Inference Server. It efficiently serves machine learning models with support for HTTP and gRPC APIs, customizable routing, and seamless Kubernetes integration.
Workflow The Triton LLM Host enables your GraphRAG pipeline to use privately hosted LLMs directly from the ArangoDB Platform environment.</description></item></channel></rss>